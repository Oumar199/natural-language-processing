{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reyMjdzHZW7L"
      },
      "source": [
        "## Neural Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5S3OSr3ZW7O",
        "outputId": "37816517-9edf-4347-cb4d-5bda2b6bfcfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sAEU_axoZW7N"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import nltk\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Embedding\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from pickle import dump, load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtDkvqluZW7O"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h55WZYovZW7O"
      },
      "outputs": [],
      "source": [
        "data = \"\"\"\n",
        "    The sixth European Union (EU) and African Union (AU) Summit taking place in Brussels this week could not have come at a more critical moment.\n",
        "    Of the 20 countries the International Rescue Committee (IRC) has identified as at greatest risk of a new,\n",
        "    or significantly worsened, humanitarian crisis in the year ahead, more than half are in Africa.\n",
        "    The African continent is also home to almost one-third of the world’s refugees.\n",
        "    Meanwhile, just 11 percent of Africa’s population is fully vaccinated from COVID-19, in stark contrast with 70 percent in the EU.\n",
        "    Given that the pandemic has undermined years of hard-won progress by African communities, civil society and governments towards the Sustainable Development Goals,\n",
        "    both the EU and AU must urgently get this important work back on track – jointly driving progress towards a more resilient and sustainable future for the African continent.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWZ3hl8LZW7P"
      },
      "source": [
        "Assigned a unique integer to each word in the text convert the sequences of words to sequences of integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UPNI_xmDZW7P"
      },
      "outputs": [],
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "encoded = tokenizer.texts_to_sequences([data])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kmfNy0ZW7P"
      },
      "source": [
        "Get the size of the vocabulary to use later to determine the size of the embeddings.  \n",
        "We add 1 to ensure the words are number from 1 to 22 rather than 0 to 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1YmTZzMZW7P",
        "outputId": "1e2b664d-1eaf-49b6-ded7-1ca43094fd8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 106\n"
          ]
        }
      ],
      "source": [
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3wxmw_ZZW7Q"
      },
      "source": [
        "Create sequences of words to fit the model with one word as input and one word as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfCoukkZW7Q",
        "outputId": "873a8ffa-199a-4e2e-81ba-ce07db0a8009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sequences: 145\n"
          ]
        }
      ],
      "source": [
        "# create word -> word sequences\n",
        "sequences = list()\n",
        "for i in range(1, len(encoded)):\n",
        "    sequence = encoded[i-1:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print('Total Sequences: %d' % len(sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_9dKsisZW7Q",
        "outputId": "0285a111-2bdd-409e-bd2d-561464380efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 2\n"
          ]
        }
      ],
      "source": [
        "# pad input sequences\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "print('Max Sequence Length: %d' % max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input => matrix or tensor dim nxm\n",
        "\n",
        "# # word embd dim = 10\n",
        "\n",
        "# this is sent 1 = > 4 [10 x 4]\n",
        "# this is sent 2 becuase => 5 [10 x 5]\n",
        "# this can also be sent 3 => 6 [10 x 6]\n",
        "\n",
        "# # padding\n",
        "# this is sent 1 <pad> <pad> => 6 [10 x 6]\n",
        "# this is sent 2 becuase <pad> => 6 [10 x 6]\n",
        "# this can also be sent 3 => 6 [10 x 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qWt3UIAYZW7Q"
      },
      "outputs": [],
      "source": [
        "# split sequence into input X and output y\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,0], sequences[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "renIGylbZW7Q",
        "outputId": "2662098c-97d8-4936-e030-346d70c93589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((145,), (145,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm9EKhqeZW7Q"
      },
      "source": [
        "To fit a model to predict a probability distribution across all words in the vocabulary. We need to turn the output element (y) from a single integer into a one hot encoding with a 0 for every word in the vocabulary and a 1 for the actual word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VhdEMCdPZW7Q"
      },
      "outputs": [],
      "source": [
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXNMEtUaZW7Q"
      },
      "source": [
        "### Train neural language model (one word in one word out)\n",
        "Model properties\n",
        "- model has an embedding layer to learn the word embedding\n",
        "- the input sequence contains a single word therefore input_length = 1\n",
        "- the model has a single LSTM layer with 50 units\n",
        "- output layer has a softmax activation function and is comprised of one neuron for each word in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pSRiT3ubZW7Q"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "def define_model(vocab_size):\n",
        "    \"\"\"Define the Deep learning \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 10, input_length=1))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "    # compile network\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j05gUwyZW7R",
        "outputId": "044a61d0-672c-4a79-c1eb-50c2237e01af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 10)             1060      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                12200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 106)               5406      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,666\n",
            "Trainable params: 18,666\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 3s 9ms/step - loss: 4.6637 - accuracy: 0.0138 \n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.6612 - accuracy: 0.0690\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.6594 - accuracy: 0.0690\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.6578 - accuracy: 0.0690\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4.6558 - accuracy: 0.0690\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x785988622dd0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model(vocab_size)\n",
        "model.fit(X, y, epochs=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6c5YZQF2ZW7R"
      },
      "outputs": [],
      "source": [
        "# # evaluate\n",
        "# in_text = 'went'\n",
        "# print(in_text)\n",
        "\n",
        "# encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "# encoded = np.array(encoded)\n",
        "# yhat = np.argmax(model.predict(encoded), axis=-1)\n",
        "# for word, index in tokenizer.word_index.items():\n",
        "#     if index == yhat:\n",
        "#         print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8IzCXJZW7R"
      },
      "source": [
        "## Language model multiple input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lLSleIJZW7R"
      },
      "source": [
        "### Read and clean document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FcPPpKmNZW7R"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "    \"\"\"Clean text\"\"\"\n",
        "    doc = doc.replace('--', ' ')\n",
        "    tokens = doc.split() # split into tokens by white space\n",
        "    table = str.maketrans('', '', string.punctuation) # remove punctuation\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    tokens = [word for word in tokens if word.isalpha()] # remove non-alphabetic tokens\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename, 'w')\n",
        "    file.write(data)\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6R7bxRTZe7e",
        "outputId": "7a1369bb-8bcf-4e1c-a5a8-f54fcb2c4efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH_BASE = \"/content/drive/My Drive/Colab Notebooks/artifacts/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0LpnJYLNZW7R"
      },
      "outputs": [],
      "source": [
        "filename = os.path.join(PATH_BASE, 'data/republic_clean.txt')\n",
        "file = open(filename, 'r')\n",
        "doc = file.read()\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1BTDUj3ZW7R",
        "outputId": "528ced8c-418d-4026-832e-cc78f99c4f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'republic', 'by', 'plato', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no']\n",
            "Total Tokens: 216791\n",
            "Unique Tokens: 10454\n"
          ]
        }
      ],
      "source": [
        "# clean document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:20])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZSavICkgZW7R"
      },
      "outputs": [],
      "source": [
        "# tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trQP8KO-ZW7R",
        "outputId": "9122b199-ee0d-481f-b24e-d82c00df320b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sequences: 216740\n"
          ]
        }
      ],
      "source": [
        "# organize into sequences of tokens\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "    # select sequence of tokens\n",
        "    seq = tokens[i-length:i]\n",
        "\n",
        "    # convert into a line\n",
        "    line = ' '.join(seq)\n",
        "    sequences.append(line)\n",
        "\n",
        "print('Total Sequences: %d' % len(sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9QIyhYVZW7R",
        "outputId": "52493ad6-5d6a-40e3-b720-e1847f03e51a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online',\n",
              " 'project gutenberg ebook of the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at',\n",
              " 'gutenberg ebook of the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg',\n",
              " 'ebook of the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title',\n",
              " 'of the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the',\n",
              " 'the republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic',\n",
              " 'republic by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author',\n",
              " 'by plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato',\n",
              " 'plato this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator',\n",
              " 'this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b',\n",
              " 'ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett',\n",
              " 'is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting',\n",
              " 'for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date',\n",
              " 'the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august',\n",
              " 'use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook',\n",
              " 'of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook release',\n",
              " 'anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook release date',\n",
              " 'anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook release date october',\n",
              " 'at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook release date october last',\n",
              " 'no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the republic author plato translator b jowett posting date august ebook release date october last updated']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e-M3KzM1ZW7S"
      },
      "outputs": [],
      "source": [
        "# save sequences to file\n",
        "out_filename = os.path.join(PATH_BASE, 'data/republic_sequences.txt')\n",
        "save_doc(sequences, out_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtXl6C58ZW7S"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VKvTo1sUZW7S"
      },
      "outputs": [],
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0xQmKZJPZW7S"
      },
      "outputs": [],
      "source": [
        "# load\n",
        "in_filename = os.path.join(PATH_BASE, 'data/republic_sequences.txt')\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aA3Qz3amZW7S"
      },
      "outputs": [],
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eoudBKqZW7S",
        "outputId": "d2d73564-a177-4b84-8a8e-bb8e1968f49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10455\n"
          ]
        }
      ],
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CG4rw1XtZW7S"
      },
      "outputs": [],
      "source": [
        "# separate into input and output\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "seq_length = X.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TROHuC0dZW7S",
        "outputId": "e7a843d9-c53c-449e-bf72-9701e706e445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((216740, 50), (216740, 10455))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9NXoc3ZW7S",
        "outputId": "7a8ca51e-efcf-4332-d920-a6c820bc1cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 50)            522750    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 100)           60400     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10455)             1055955   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,729,605\n",
            "Trainable params: 1,729,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNp587S0ZW7S",
        "outputId": "e8903752-a958-4f52-fd66-a807161a8990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1694/1694 [==============================] - 587s 344ms/step - loss: 6.1534 - accuracy: 0.0960\n",
            "Epoch 2/2\n",
            "1694/1694 [==============================] - 611s 361ms/step - loss: 5.6468 - accuracy: 0.1353\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7859886cc790>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compile and fit\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HTB7rmXUZW7S"
      },
      "outputs": [],
      "source": [
        "# save the model to file\n",
        "model_path = os.path.join(PATH_BASE, 'model/lecture_6/llm_model.h5')\n",
        "model.save(model_path)\n",
        "\n",
        "# save the tokenizer\n",
        "tokenizer_path = os.path.join(PATH_BASE, 'model/lecture_6/tokenizer.pkl')\n",
        "dump(tokenizer, open(tokenizer_path, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdobX5uaZW7b"
      },
      "source": [
        "### Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "krrdruUMZW7b"
      },
      "outputs": [],
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    # generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "        # encode the text as integer and truncate sequences to a fixed length\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "        # map predicted word index to word\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "\n",
        "        # append to input\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "H7XV57uJZW7c"
      },
      "outputs": [],
      "source": [
        "# # load the model\n",
        "# model = load_model(model_path)\n",
        "\n",
        "# # load the tokenizer\n",
        "# tokenizer = load(open(tokenizer_path, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lnjQDAMWZW7c"
      },
      "outputs": [],
      "source": [
        "# load cleaned text sequences\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5_8693sZW7c",
        "outputId": "d80d13b1-bee9-4dcf-acd5-5df3c3d2e1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "but will not enslave or destroy their opponents they will be correctors not enemies just so and as they are hellenes themselves they will not devastate hellas nor will they burn houses nor ever suppose that the whole population of a city men women and children are equally their enemies for\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# select a seed text\n",
        "idx = randint(0,len(lines))\n",
        "seed_text = lines[idx]\n",
        "print(seed_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7bOg4LeZW7c",
        "outputId": "6e706c72-1e6d-4a76-ea05-61981e173e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated text\n",
            "the state of the state and the state of the state and the state of the state and the state of the state and the state of the state and the state of the state and the state of the state and the state of the state and the state\n"
          ]
        }
      ],
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print('generated text')\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "e67dIPCHZW7c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
